{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4daf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# grab credentials from the notebook user\n",
    "host = input(\"Host name\")\n",
    "username = input(\"User name\")\n",
    "password = getpass.getpass(\"Password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2854047d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Working='Yes')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pystarburst import Session\n",
    "from pystarburst import functions as F\n",
    "from pystarburst.functions import *\n",
    "from pystarburst.window import Window as W\n",
    "\n",
    "# PyStarburst setup\n",
    "session_properties = {\n",
    "    \"host\":host,\n",
    "    \"port\": 443,\n",
    "    \"http_scheme\": \"https\",\n",
    "    \"auth\": trino.auth.BasicAuthentication(username, password)\n",
    "}\n",
    "session = Session.builder.configs(session_properties).create()\n",
    "\n",
    "# validate PyStarburst working\n",
    "session.sql(\"select 'Yes' as Working\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a730bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Yes']]\n"
     ]
    }
   ],
   "source": [
    "from trino.dbapi import connect\n",
    "\n",
    "# trino-python-client setup\n",
    "conn = connect(\n",
    "    host=host,\n",
    "    port=443,\n",
    "    http_scheme='https',\n",
    "    auth=trino.auth.BasicAuthentication (username, password)\n",
    ")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"select 'Yes' as dummy\")\n",
    "\n",
    "# validate trino-python-client working\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a05ed28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['students.mv2ice.t_ice_orc', 'students.mv2ice.t_ice_parquet', 'students.mv2ice.t_hive_json']\n"
     ]
    }
   ],
   "source": [
    "# LATER can pass in a catalog to work on\n",
    "curr_cat = 'students'\n",
    "# LATER can get a list of the schemas to loop through\n",
    "curr_sch = 'mv2ice'\n",
    "\n",
    "table_list_from_collect = session \\\n",
    "    .table(curr_cat + \".information_schema.tables\") \\\n",
    "    .filter(\"table_schema = '\" + curr_sch + \"' AND table_type = 'BASE TABLE'\") \\\n",
    "    .select(\"table_name\") \\\n",
    "    .collect()\n",
    "\n",
    "table_list = list()\n",
    "for a_table in table_list_from_collect:\n",
    "    table_list.append(curr_cat + \".\" + curr_sch + \".\" + a_table.table_name)\n",
    "\n",
    "# debug line to see the tables to investigate\n",
    "print(table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "183f6287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE students.mv2ice.t_ice_orc (\n",
      "   nationkey bigint,\n",
      "   name varchar,\n",
      "   regionkey bigint,\n",
      "   comment varchar\n",
      ")\n",
      "WITH (\n",
      "   format = 'ORC',\n",
      "   format_version = 2,\n",
      "   location = 's3://edu-train-galaxy-students/students/mv2ice/t_ice_orc-2b2ed747bb28485685b3610295894e87',\n",
      "   type = 'ICEBERG'\n",
      ")\n",
      "\n",
      "CREATE TABLE students.mv2ice.t_ice_parquet (\n",
      "   nationkey bigint,\n",
      "   name varchar,\n",
      "   regionkey bigint,\n",
      "   comment varchar\n",
      ")\n",
      "WITH (\n",
      "   format = 'PARQUET',\n",
      "   format_version = 2,\n",
      "   location = 's3://edu-train-galaxy-students/students/mv2ice/t_ice_parquet-ecfe974580114948859ceafe1fc11f51',\n",
      "   type = 'ICEBERG'\n",
      ")\n",
      "\n",
      "CREATE TABLE students.mv2ice.t_hive_json (\n",
      "   nationkey bigint,\n",
      "   name varchar(25),\n",
      "   regionkey bigint,\n",
      "   comment varchar(152)\n",
      ")\n",
      "WITH (\n",
      "   format = 'JSON',\n",
      "   type = 'HIVE'\n",
      ")\n",
      "\n",
      "2 Iceberg tables already exist -- no action will be taken on these...\n",
      "['students.mv2ice.t_ice_orc', 'students.mv2ice.t_ice_parquet']\n",
      "\n",
      "0 non Iceberg or Hive tables exist -- no action will be taken on these (BUT COULD BE REWRITTEN)...\n",
      "[]\n",
      "\n",
      "0 Hive tables that are targeted to be MIGRATED (in-place) to Iceberg...\n",
      "[]\n",
      "\n",
      "1 Hive tables are targeted to be REWRITTEN (ctas) to Iceberg...\n",
      "['students.mv2ice.t_hive_json']\n"
     ]
    }
   ],
   "source": [
    "# create some lists to separate the table types into\n",
    "hive_tables_2rewrite = list()\n",
    "hive_tables_2migrate = list()\n",
    "iceberg_tables = list()\n",
    "other_tables   = list()\n",
    "\n",
    "# could NOT get the SHOW CREATE TABLE output via PyStarburst \n",
    "#  OR figure out how to get the table format type in other way\n",
    "#  SO using trino-python-client\n",
    "\n",
    "for a_table in table_list:\n",
    "    cur.execute(\"SHOW CREATE TABLE \" + a_table)\n",
    "    cts = cur.fetchall()[0][0]\n",
    "    \n",
    "    # rm me\n",
    "    print(\"\\n\" + cts)\n",
    "    # rm me\n",
    "    \n",
    "    if \"type = 'HIVE'\" in cts:\n",
    "        if \"format = 'PARQUET'\" in cts or \"format = 'ORC'\" in cts or \"format = 'AVRO'\" in cts:\n",
    "            hive_tables_2migrate.append(a_table)\n",
    "        else:\n",
    "            hive_tables_2rewrite.append(a_table)\n",
    "    elif \"type = 'ICEBERG'\" in cts:\n",
    "        iceberg_tables.append(a_table)\n",
    "    else:\n",
    "        other_tables.append(a_table)\n",
    "        \n",
    "        \n",
    "print(\"\\n\" + str(len(iceberg_tables)) + \" Iceberg tables already exist -- no action will be taken on these...\")\n",
    "print(iceberg_tables)\n",
    "\n",
    "print(\"\\n\" + str(len(other_tables)) + \" non Iceberg or Hive tables exist -- no action will be taken on these \" + \\\n",
    "      \"(BUT COULD BE REWRITTEN)...\")\n",
    "print(other_tables)\n",
    "\n",
    "print(\"\\n\" + str(len(hive_tables_2migrate)) + \" Hive tables that are targeted to be MIGRATED (in-place) to Iceberg...\")\n",
    "print(hive_tables_2migrate)\n",
    "\n",
    "print(\"\\n\" + str(len(hive_tables_2rewrite)) + \" Hive tables are targeted to be REWRITTEN (ctas) to Iceberg...\")\n",
    "print(hive_tables_2rewrite)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a539236e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
